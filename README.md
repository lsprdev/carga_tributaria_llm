# üìä Carga Tribut√°ria LLM

Este √© um projeto de demonstra√ß√£o de **RAG (Retrieval-Augmented Generation)** utilizando **LangChain**, **Ollama**, **FAISS** e **Streamlit** para permitir consultas inteligentes a dados tribut√°rios estruturados (CSV) e semiestruturados (PDFs).

## üîß Tecnologias Utilizadas

- [LangChain](https://www.langchain.com/)
- [Ollama](https://ollama.com/)
- [FAISS](https://github.com/facebookresearch/faiss)
- [Streamlit](https://streamlit.io/)
- [Pandas](https://pandas.pydata.org/)

## üìÅ Estrutura de Pastas

```
carga_tributaria_llm/
‚îÇ
‚îú‚îÄ‚îÄ core/                      # M√≥dulos principais do sistema
‚îÇ   ‚îú‚îÄ‚îÄ constants.py           # Caminhos e constantes globais
‚îÇ   ‚îú‚îÄ‚îÄ document_loader.py     # Carregamento e convers√£o de CSV e PDF para documentos LangChain
‚îÇ   ‚îú‚îÄ‚îÄ vectorstore_manager.py # Indexa√ß√£o e carregamento do vetor FAISS
‚îÇ   ‚îú‚îÄ‚îÄ llm_service.py         # Interface com o modelo LLM via Ollama
‚îÇ   ‚îú‚îÄ‚îÄ utils.py               # Fun√ß√µes utilit√°rias (ex: limpeza de texto)
‚îÇ
‚îú‚îÄ‚îÄ datasets/                  # Arquivos de dados
‚îÇ   ‚îú‚îÄ‚îÄ *.csv                  # Tabelas tribut√°rias
‚îÇ   ‚îú‚îÄ‚îÄ *.pdf                  # Metadados das tabelas
‚îÇ
‚îú‚îÄ‚îÄ faiss_datasets/            # Persist√™ncia do √≠ndice FAISS
‚îÇ
‚îú‚îÄ‚îÄ app.py                     # Aplica√ß√£o principal Streamlit
‚îú‚îÄ‚îÄ requirements.txt           # Depend√™ncias do projeto
‚îú‚îÄ‚îÄ README.md                  # Este arquivo
‚îî‚îÄ‚îÄ .gitignore                 # Exclus√µes do Git
```

## üöÄ Como Executar

### 1. Requisitos

- Python 3.10+
- Ambiente virtual configurado
- [Ollama instalado e rodando](https://ollama.com/)

### 2. Instala√ß√£o

```bash
git clone https://github.com/lsprdev/carga_tributaria_llm.git
cd carga_tributaria_llm
python -m venv venv
source venv/bin/activate  # No Windows: venv\Scripts\activate
pip install -r requirements.txt
```

### 3. Executar a aplica√ß√£o
```bash
streamlit run app.py
```

> O sistema ir√° carregar ou construir automaticamente o √≠ndice FAISS a partir dos arquivos CSV e PDF na pasta `datasets/`.

## üí° Como Funciona?

1. Os arquivos CSV e PDF s√£o carregados como documentos LangChain.
2. √â criado um √≠ndice vetorial FAISS com embeddings via `nomic-embed-text` (Ollama).
3. O usu√°rio digita uma pergunta na interface Streamlit.
4. O sistema busca os documentos relevantes e envia o contexto ao modelo LLM (`deepseek-r1:8b`).
5. O modelo retorna uma resposta com base nos dados.

## üìå Observa√ß√µes

- O modelo precisa estar carregado localmente via Ollama (`ollama run deepseek-r1:8b`).
- O carregamento inicial pode levar alguns segundos, pois envolve leitura e indexa√ß√£o de documentos.
- O sistema ainda √© uma prova de conceito e pode ser expandido para adicionar upload de arquivos ou hist√≥rico de respostas.